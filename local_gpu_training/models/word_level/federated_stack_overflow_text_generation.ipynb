{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level Federated Text Generation with Stack Overflow (NOT WORKING YET)\n",
    "- Joel Stremmel\n",
    "- 01-20-20\n",
    "\n",
    "**About:**\n",
    "\n",
    "This notebook loads the Stack Overflow data available through `tff.simulation.datasets` and trains an LSTM model with Federared Averaging by following the Federated Learning for Text Generation [example notebook](https://github.com/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_text_generation.ipynb).\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "This notebook prepares the Stack Overflow dataset for word level language modeling using this [module](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/baselines/stackoverflow/dataset.py\n",
    ").\n",
    "\n",
    "\n",
    "**Data:** \n",
    "- https://www.kaggle.com/stackoverflow/stackoverflow\n",
    "\n",
    "**License:** \n",
    "- https://creativecommons.org/licenses/by-sa/3.0/\n",
    "\n",
    "**Data and Model References:**\n",
    "- https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/stackoverflow/load_data\n",
    "- https://github.com/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_text_generation.ipynb\n",
    "- https://github.com/tensorflow/federated/\n",
    "- https://www.tensorflow.org/tutorials/text/text_generation\n",
    "- https://ruder.io/deep-learning-nlp-best-practices/\n",
    "\n",
    "**Environment Setup References:**\n",
    "- https://www.tensorflow.org/install/gpu\n",
    "- https://gist.github.com/matheustguimaraes/43e0b65aa534db4df2918f835b9b361d\n",
    "- https://www.tensorflow.org/install/source#tested_build_configurations\n",
    "- https://anbasile.github.io/programming/2017/06/25/jupyter-venv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "Pip install these packages in the order listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade tensorflow-federated\n",
    "# !pip uninstall tensorflow -y\n",
    "# !pip install --upgrade tensorflow-gpu==2.0\n",
    "# !pip install --upgrade nltk\n",
    "# !pip install matplotlib\n",
    "# !pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/baselines/stackoverflow/dataset.py\n",
    "from utils.dataset import construct_word_level_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import six\n",
    "import time\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Compatability Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Tensorflow Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Built with Cuda: {}'.format(tf.test.is_built_with_cuda()))\n",
    "print('Build with GPU support: {}'.format(tf.test.is_built_with_gpu_support()))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Tensorflow to Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices(device_type=None)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[-1], enable=True)\n",
    "for device in physical_devices:\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test TFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Some Parameters for Preprocessing the Data and Training the Model\n",
    "**Note:** Ask Keith how he's been setting there for internal experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "BATCH_SIZE = 16\n",
    "CLIENTS_EPOCHS_PER_ROUND = 1\n",
    "MAX_SEQ_LENGTH = 100\n",
    "MAX_ELEMENTS_PER_USER = 100\n",
    "CENTRALIZED_TRAIN = False\n",
    "SHUFFLE_BUFFER_SIZE = 5000\n",
    "NUM_VALIDATION_EXAMPLES = 200\n",
    "NUM_TEST_EXAMPLES = 200\n",
    "\n",
    "NUM_ROUNDS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = construct_word_level_datasets(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    client_epochs_per_round=CLIENTS_EPOCHS_PER_ROUND,\n",
    "    max_seq_len=MAX_SEQ_LENGTH,\n",
    "    max_elements_per_user=MAX_ELEMENTS_PER_USER,\n",
    "    centralized_train=CENTRALIZED_TRAIN,\n",
    "    shuffle_buffer_size=SHUFFLE_BUFFER_SIZE,\n",
    "    num_validation_examples=NUM_VALIDATION_EXAMPLES,\n",
    "    num_test_examples=NUM_TEST_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Number of Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} train clients.'.format(len(train_data.client_ids)))\n",
    "print('{} val clients.'.format(len(val_data.client_ids)))\n",
    "print('{} test clients.'.format(len(test_data.client_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Vocabulary\n",
    "- Currently using the fixed vocabularly of ASCII chars that occur in the works of Shakespeare and Dickens\n",
    "- **Is there a good way to get the distinct characters from a TF dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list('dhlptx@DHLPTX $(,048cgkoswCGKOSW[_#\\'/37;?bfjnrvzBFJNRVZ\"&*.26:\\naeimquyAEIMQUY]!%)-159\\r')\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Mapping from Unique Characters to Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(batch_size, vocab_size, seq_length, embedding_dim=256, rnn_units=512):\n",
    "    \"\"\"\n",
    "    Build model with architecture from: https://www.tensorflow.org/tutorials/text/text_generation.\n",
    "    \"\"\"\n",
    "\n",
    "    model1_input = tf.keras.Input(shape=(seq_length, ),\n",
    "                                  name='model1_input')\n",
    "    \n",
    "    model1_embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                 output_dim=embedding_dim,\n",
    "                                                 input_length=seq_length,\n",
    "                                                 batch_input_shape=[batch_size, None],\n",
    "                                                 name='model1_embedding')(model1_input)\n",
    "    \n",
    "    model1_lstm = tf.keras.layers.LSTM(units=rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       recurrent_initializer='glorot_uniform',\n",
    "                                       name='model1_lstm')(model1_embedding)\n",
    "    \n",
    "    model1_dense = tf.keras.layers.Dense(units=vocab_size)(model1_lstm)\n",
    "    \n",
    "    final_model = tf.keras.Model(inputs=model1_input, outputs=model1_dense)\n",
    "                 \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Text Generation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    \"\"\"\n",
    "    Generate text by sampling from the model output distribution\n",
    "    as in From https://www.tensorflow.org/tutorials/sequences/text_generation.\n",
    "    \"\"\"\n",
    "\n",
    "    num_generate = 200\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    temperature = 1.0\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load or Build the Model\n",
    "Text generation requires a batch_size=1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras_model_batch1 = build_model(batch_size=1, vocab_size=vocab_size, seq_length=SEQ_LENGTH)\n",
    "print(generate_text(keras_model_batch1, \"How's the water today? \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions to Preprocess Federated Stack Overflow\n",
    "- Using a namedtuple with keys x and y as the output type of the dataset keeps both TFF and Keras happy.\n",
    "- Construct a lookup table to map string chars to indexes, using the vocab loaded above.\n",
    "- Write functions for:\n",
    "    - ID lookup\n",
    "    - Splitting inputs and targets\n",
    "    - Applying preprocessing steps to dataset\n",
    "    - Taking clients and client records and applying preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchType = collections.namedtuple('BatchType', ['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=vocab,\n",
    "        values=tf.constant(list(range(len(vocab))),\n",
    "        dtype=tf.int64)),\n",
    "    default_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ids(x):\n",
    "    \n",
    "    s = tf.reshape(x['tokens'], shape=[1])\n",
    "    chars = tf.strings.bytes_split(s).values\n",
    "    ids = table.lookup(chars)\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    \n",
    "    input_text = tf.map_fn(lambda x: x[:-1], chunk)\n",
    "    target_text = tf.map_fn(lambda x: x[1:], chunk)\n",
    "    \n",
    "    return BatchType(input_text, target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    \n",
    "    return (\n",
    "        # Map ASCII chars to int64 indexes using the vocab\n",
    "        dataset.map(to_ids)\n",
    "        # Split into individual chars\n",
    "        .unbatch()\n",
    "        # Form example sequences of SEQ_LENGTH +1\n",
    "        .batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
    "        # Shuffle and form minibatches\n",
    "        .shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "        # And finally split into (input, target) tuples,\n",
    "        # each of length SEQ_LENGTH.\n",
    "        .map(split_input_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_for_client(client, data_source):\n",
    "    \n",
    "    return preprocess(data_source.create_tf_dataset_for_client(client))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sample Clients for Validation and Testing\n",
    "Note that the train clients will be sampled within the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_clients(dataset, num_clients):\n",
    "    \n",
    "    random_indices = np.random.choice(len(dataset.client_ids), size=num_clients, replace=False)\n",
    "    \n",
    "    return np.array(dataset.client_ids)[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_clients = get_sample_clients(val_data, num_clients=NUM_VAL_CLIENTS)\n",
    "test_clients = get_sample_clients(test_data, num_clients=NUM_TEST_CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Preprocess the Validation and Test Datasets\n",
    "Concatenate the validation and test datasets for evaluation with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = functools.reduce(lambda d1, d2: d1.concatenate(d2), \n",
    "                               [preprocess_data_for_client(client, val_data) for client in val_clients])\n",
    "\n",
    "test_dataset = functools.reduce(lambda d1, d2: d1.concatenate(d2), \n",
    "                                [preprocess_data_for_client(client, test_data) for client in test_clients])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Lists to Track Loss and Accuracy at Each Training Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "val_loss = []\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Evaluation Function to Use During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_evaluate(keras_model, state, val_dataset):\n",
    "    \n",
    "    tff.learning.assign_weights_to_keras_model(keras_model, state.model)\n",
    "    loss, accuracy = keras_model.evaluate(val_dataset, steps=2)\n",
    "    \n",
    "    val_loss.append(loss)\n",
    "    val_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenedCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "\n",
    "    def __init__(self, name='accuracy', dtype=None):\n",
    "        super(FlattenedCategoricalAccuracy, self).__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        y_true = tf.reshape(y_true, [-1, 1])\n",
    "        y_pred = tf.reshape(y_pred, [-1, len(vocab), 1])\n",
    "        \n",
    "        return super(FlattenedCategoricalAccuracy, self).update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile(keras_model):\n",
    "    \n",
    "    keras_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[FlattenedCategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Compile the Model\n",
    "The keras model will be accessed as a global variable to create a copy to be called by TFF and will be updated within the training loop to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = build_model(batch_size=BATCH_SIZE,\n",
    "                          vocab_size=vocab_size,\n",
    "                          seq_length=SEQ_LENGTH)\n",
    "compile(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TFF Version of the Model to be Trained with Federated Averaging\n",
    "- Clone the keras_model inside `create_tff_model()`, which TFF will call to produce a new copy of the model inside the graph that it will serialize.\n",
    "- TFF uses a `dummy_batch` so it knows the types and shapes that your model expects.\n",
    "- Build and serialize the Tensorflow graph with `build_federated_averaging_process`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tff_model():\n",
    "    \n",
    "    x = tf.constant(np.random.randint(1, len(vocab), size=[BATCH_SIZE, SEQ_LENGTH]))\n",
    "    dummy_batch = collections.OrderedDict([('x', x), ('y', x)]) \n",
    "    keras_model_clone = compile(tf.keras.models.clone_model(keras_model))\n",
    "    \n",
    "    return tff.learning.from_compiled_keras_model(keras_model_clone, dummy_batch=dummy_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_avg = tff.learning.build_federated_averaging_process(model_fn=create_tff_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Federated Averaging Process and the Starting Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: If the statement below fails, it means that you are\n",
    "# using an older version of TFF without the high-performance\n",
    "# executor stack. Call `tff.framework.set_default_executor()`\n",
    "# instead to use the default reference runtime.\n",
    "if six.PY3:\n",
    "    tff.framework.set_default_executor(tff.framework.create_local_executor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The state of the FL server, containing the model and optimization state.\n",
    "state = fed_avg.initialize()\n",
    "\n",
    "state = tff.learning.state_with_new_model_weights(\n",
    "    state,\n",
    "    trainable_weights=[v.numpy() for v in keras_model.trainable_weights],\n",
    "    non_trainable_weights=[v.numpy() for v in keras_model.non_trainable_weights]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model Across Many Randomly Sampled Clients with Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for round_num in range(NUM_ROUNDS):\n",
    "    \n",
    "    # Examine validation metrics\n",
    "    print(f'Evaluating before training round #{round_num} on {NUM_VAL_CLIENTS} clients.')\n",
    "    keras_evaluate(keras_model, state, val_dataset)\n",
    "    \n",
    "    # Sample train clients to create a train dataset\n",
    "    print(f'Sampling {NUM_TRAIN_CLIENTS} new clients.')\n",
    "    train_clients = get_sample_clients(train_data, num_clients=NUM_TRAIN_CLIENTS)\n",
    "    train_datasets = [preprocess_data_for_client(client, train_data) for client in train_clients]\n",
    "    \n",
    "    # Apply federated training round\n",
    "    print('Applying federated training round.')\n",
    "    state, metrics = fed_avg.next(state, train_datasets)\n",
    "    \n",
    "    # Examine training metrics\n",
    "    print(f'Training metrics - loss: {metrics[1]:4.4f}; accuracy: {metrics[0]:4.4f}')\n",
    "    train_loss.append(metrics[1])\n",
    "    train_accuracy.append(metrics[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_axis = range(0, NUM_ROUNDS)\n",
    "ax.plot(x_axis, train_loss, label='Train')\n",
    "ax.plot(x_axis, val_loss, label='Validation')\n",
    "ax.legend(loc='best')\n",
    "plt.ylabel('Value of Objective Function')\n",
    "plt.title('Model Objective Function at Each Training Round')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_axis = range(0, NUM_ROUNDS)\n",
    "ax.plot(x_axis, train_accuracy, label='Train')\n",
    "ax.plot(x_axis, val_accuracy, label='Validation')\n",
    "ax.legend(loc='best')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy at Each Training Round')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_evaluate(keras_model, state, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text\n",
    "Text generation requires batch_size=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_batch1.set_weights([v.numpy() for v in keras_model.weights])\n",
    "print(generate_text(keras_model_batch1, \"How's the water today? \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggested extensions:**\n",
    "\n",
    "- Use \".repeat(NUM_EPOCHS)\" on the client datasets to try multiple epochs of local training (e.g., as in McMahan et. al.). See also Federated Learning for Image Classification which does this.\n",
    "- Change the compile() command to experiment with using different optimization algorithms on the client.\n",
    "- Try the server_optimizer argument to build_federated_averaging_process to try different algorithms for applying the model updates on the server.\n",
    "- Try the client_weight_fn argument to to build_federated_averaging_process to try different weightings of the clients. The default weights client updates by the number of examples on the client, but you can do e.g. client_weight_fn=lambda _: tf.constant(1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed",
   "language": "python",
   "name": "fed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
