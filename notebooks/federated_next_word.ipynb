{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level Federated Text Generation with Stack Overflow with Randomly Initialized or Pretrained Word Embeddings\n",
    "- Joel Stremmel\n",
    "- 02-20-20\n",
    "- Runs on GCP and local Ubuntu 16.04\n",
    "\n",
    "**About:**\n",
    "\n",
    "This notebook loads the Stack Overflow data available through `tff.simulation.datasets` and trains an LSTM model with Federared Averaging by following the Federated Learning for Text Generation [example notebook](https://github.com/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_text_generation.ipynb).  The embedding layer is initialized with one of the following options by setting the `EMBEDDING_LAYER` parameter:\n",
    "- [GloVe](https://nlp.stanford.edu/projects/glove/) ([license here](https://www.opendatacommons.org/licenses/pddl/1.0/))\n",
    "- [FastText](https://fasttext.cc/docs/en/english-vectors.html) ([license here](https://creativecommons.org/licenses/by-sa/3.0/))\n",
    "- [GPT-2](https://openai.com/blog/better-language-models/) ([license here](https://github.com/huggingface/transformers/blob/master/LICENSE))\n",
    "- [Randomly initialized embeddings](https://www.tensorflow.org/api_docs/python/tf/random_uniform_initializer)  \n",
    "\n",
    "After downloading the GloVe or FastText embeddings, place the embedding files at the top level of the repository in directories called `word_embedding/glove` and `word_embedding/fasttext` respectively.  GPT-2 embeddings are downloaded by running the notebook which makes a call to `src/embeddings.py` to download the embeddings from [huggingface](https://github.com/huggingface/transformers).  \n",
    "\n",
    "**Code from Tensorflow Federated:**\n",
    "\n",
    "- This notebook prepares the Stack Overflow dataset for word level language modeling using this [module](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/baselines/stackoverflow/dataset.py\n",
    ").\n",
    "- The metrics for model training come from this [module](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/baselines/stackoverflow/metrics.py). \n",
    "\n",
    "\n",
    "**Data and Model References:**\n",
    "- [TFF Stack Overflow `load_data`](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/stackoverflow/load_data)\n",
    "- [TFF text generation tutorial](https://github.com/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_text_generation.ipynb)\n",
    "- [Google TFF team research baselines for Stack Overflow](https://github.com/tensorflow/federated/tree/master/tensorflow_federated/python/research/baselines/stackoverflow)\n",
    "- [Tensorflow text generation tutorial](https://www.tensorflow.org/tutorials/text/text_generation)\n",
    "\n",
    "**Environment Setup References:**\n",
    "- [Installing Tensorflow for GPU](https://www.tensorflow.org/install/gpu)\n",
    "- [Install CUDA 10.0 and cuDNN v7.4.2 on Ubuntu 16.04](https://gist.github.com/matheustguimaraes/43e0b65aa534db4df2918f835b9b361d)\n",
    "- [Tensorflow build configs](https://www.tensorflow.org/install/source#tested_build_configurations)\n",
    "- [Using jupyter notebooks with a virtual environment](https://anbasile.github.io/programming/2017/06/25/jupyter-venv/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, io\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import six\n",
    "import time\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import dataset, metrics, embeddings, model, validation, federated, generate_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Some Parameters for Preprocessing the Data and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "BATCH_SIZE = 16\n",
    "CLIENTS_EPOCHS_PER_ROUND = 1\n",
    "MAX_SEQ_LENGTH = 20\n",
    "MAX_ELEMENTS_PER_USER = 5000\n",
    "CENTRALIZED_TRAIN = False\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "NUM_VALIDATION_EXAMPLES = 10000\n",
    "NUM_TEST_EXAMPLES = 2\n",
    "\n",
    "NUM_ROUNDS = 50\n",
    "NUM_TRAIN_CLIENTS = 10\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "RNN_UNITS = 128\n",
    "\n",
    "EMBEDDING_LAYER = 'pp_pca_pp_gpt2'\n",
    "SAV = 'embedding_layer_results/{}_{}_{}_{}/'.format(EMBEDDING_LAYER, \n",
    "                                                    EMBEDDING_DIM, \n",
    "                                                    RNN_UNITS, \n",
    "                                                    EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Output Directory if it Nonexistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAV):\n",
    "    os.makedirs(SAV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Word Level Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = dataset.construct_word_level_datasets(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    client_epochs_per_round=CLIENTS_EPOCHS_PER_ROUND,\n",
    "    max_seq_len=MAX_SEQ_LENGTH,\n",
    "    max_elements_per_user=MAX_ELEMENTS_PER_USER,\n",
    "    centralized_train=CENTRALIZED_TRAIN,\n",
    "    shuffle_buffer_size=SHUFFLE_BUFFER_SIZE,\n",
    "    num_validation_examples=NUM_VALIDATION_EXAMPLES,\n",
    "    num_test_examples=NUM_TEST_EXAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Dataset Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dataset.get_vocab(vocab_size=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Extended Vocab Size\n",
    "We account for the following four special tokens applied during preprocessing with `construct_word_level_datasets`:\n",
    "- pad: padding token\n",
    "- oov: out of vocabulary\n",
    "- bos: begin of sentence\n",
    "- eos: end of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_vocab_size = VOCAB_SIZE + len(dataset.get_special_tokens(VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding Matrix from Words in Word Index and Word Embeddings\n",
    "If the `EMBEDDING_LAYER` option is set to 'random', the embedding matrix in the embedding layer is initialized according to the random uniform distribution used by the tf.keras embedding layer by passing the 'uniform' string as an argument to the `embedding_initializer` in the `build_model` function.  Otherwise, an embedding index called `word2embedding` is created from pretrained embeddings either loaded from the 'word_embeddings' directory or created from a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDING_LAYER == 'random':\n",
    "    pass\n",
    "\n",
    "elif EMBEDDING_LAYER == 'glove':\n",
    "    embedding_path = '../word_embeddings/glove/glove.6B.{}d.txt'.format(EMBEDDING_DIM)\n",
    "    word2embedding = embeddings.load_embeddings(embedding_path)\n",
    "    \n",
    "elif EMBEDDING_LAYER == 'fasttext':\n",
    "    embedding_path = '../word_embeddings/fasttext/wiki-news-300d-1M.vec'\n",
    "    word2embedding = embeddings.load_embeddings(embedding_path)\n",
    "    \n",
    "elif EMBEDDING_LAYER == 'pca_fasttext':\n",
    "    embedding_path = '../word_embeddings/fasttext/wiki-news-300d-1M.vec'\n",
    "    word2embedding = embeddings.load_embeddings(embedding_path)\n",
    "    word2embedding = embeddings.to_pca_projections(word2embedding, vocab, EMBEDDING_DIM)\n",
    "\n",
    "elif EMBEDDING_LAYER == 'pp_pca_pp_fasttext':\n",
    "    embedding_path = '../word_embeddings/fasttext/wiki-news-300d-1M.vec'\n",
    "    word2embedding = embeddings.load_embeddings(embedding_path)\n",
    "    word2embedding = embeddings.to_pp_pca_pp_projections(word2embedding, vocab, EMBEDDING_DIM)\n",
    "    \n",
    "elif EMBEDDING_LAYER == 'gpt2':\n",
    "    word2embedding = embeddings.create_gpt_embeddings(vocab)\n",
    "    word2embedding = embeddings.to_pca_projections(word2embedding, vocab, EMBEDDING_DIM)\n",
    "\n",
    "elif EMBEDDING_LAYER == 'pca_gpt2':\n",
    "    word2embedding = embeddings.create_gpt_embeddings(vocab)\n",
    "    word2embedding = embeddings.to_pca_projections(word2embedding, vocab, EMBEDDING_DIM)\n",
    "\n",
    "elif EMBEDDING_LAYER == 'pp_pca_pp_gpt2':\n",
    "    word2embedding = embeddings.create_gpt_embeddings(vocab)\n",
    "    word2embedding = embeddings.to_pp_pca_pp_projections(word2embedding, vocab, EMBEDDING_DIM)\n",
    "    \n",
    "else:\n",
    "    layer_opts = ['random', 'glove',\n",
    "                  'fasttext', 'pca_fasttext', 'pp_pca_pp_fasttext', \n",
    "                  'gpt2', 'pca_gpt2', 'pp_pca_pp_gpt2']\n",
    "    \n",
    "    raise ValueError(\"EMBEDDING LAYER must be in {}.\".format(layer_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/Documents/dev_gear/git/fl-text-models/src/embeddings.py:80: missing_words_warning: 5 words set to default random initialization\n",
      "  .format(missing), missing_words_warning)\n"
     ]
    }
   ],
   "source": [
    "if EMBEDDING_LAYER == 'random':\n",
    "    embedding_matrix = 'uniform'\n",
    "else:\n",
    "    embedding_matrix = embeddings.create_matrix_from_pretrained_embeddings(\n",
    "        word2embedding=word2embedding,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        vocab=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TFF Version of the Model to be Trained with Federated Averaging\n",
    "- TFF uses a sample batch so it knows the types and shapes that your model expects.\n",
    "- The model function then builds and compiles the model and creates a TFF version to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    }
   ],
   "source": [
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(val_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Train and Validation Model Trackers to be Used Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metric_names = ['loss',\n",
    "                           'num_tokens',\n",
    "                           'num_tokens_no_oov',\n",
    "                           'num_batches',\n",
    "                           'num_examples',\n",
    "                           'accuracy',\n",
    "                           'accuracy_no_oov',\n",
    "                           'accuracy_no_oov_no_oes']\n",
    "\n",
    "train_metrics_tracker = validation.model_history_tracker(metric_names=evaluation_metric_names)\n",
    "val_metrics_tracker = validation.model_history_tracker(metric_names=evaluation_metric_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Default Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.framework.set_default_executor(tff.framework.local_executor_factory(max_fanout=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Iterative Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py:242: UserWarning: tff.learning.build_federated_averaging_process will start requiring a new argument 'client_optimizer_fn'. Specify the local client optimizer here rather than building a ttf.learning.TrainableModel\n",
      "  warnings.warn('tff.learning.build_federated_averaging_process will start '\n"
     ]
    }
   ],
   "source": [
    "iterative_process = (\n",
    "      tff.learning.federated_averaging.build_federated_averaging_process(\n",
    "          model_fn=lambda : model.model_fn(extended_vocab_size=extended_vocab_size,\n",
    "                                           embedding_dim=EMBEDDING_DIM,\n",
    "                                           embedding_matrix=embedding_matrix,\n",
    "                                           rnn_units=RNN_UNITS,\n",
    "                                           vocab_size=VOCAB_SIZE,\n",
    "                                           sample_batch=sample_batch),\n",
    "          server_optimizer_fn=federated.server_optimizer_fn,\n",
    "          #client_optimizer_fn=federated.client_optimizer_fn,\n",
    "          client_weight_fn=federated.client_weight_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize the Process\n",
    "Server state will be updated in the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model Across Many Randomly Sampled Clients with Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating before round #0 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 112ms/step - loss: 6.2440 - num_tokens: 128180.0000 - num_tokens_no_oov: 124185.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 7.8015e-05 - accuracy_no_oov: 8.0525e-05 - accuracy_no_oov_no_eos: 8.5841e-05Sampling 10 new clients.\n",
      "Round: 0\n",
      "   Loss: 7.37558365\n",
      "   num_batches: 245\n",
      "   num_examples: 3841\n",
      "   num_tokens: 49314\n",
      "   num_tokens_no_oov: 47770\n",
      "   accuracy: 0.00105\n",
      "   accuracy_no_oov: 0.00107\n",
      "Evaluating before round #1 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 6.4724 - num_tokens: 133519.0000 - num_tokens_no_oov: 129294.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0017 - accuracy_no_oov: 0.0016 - accuracy_no_oov_no_eos: 0.0017Sampling 10 new clients.\n",
      "Round: 1\n",
      "   Loss: 6.37950134\n",
      "   num_batches: 406\n",
      "   num_examples: 6419\n",
      "   num_tokens: 84814\n",
      "   num_tokens_no_oov: 82175\n",
      "   accuracy: 0.00019\n",
      "   accuracy_no_oov: 0.00015\n",
      "Evaluating before round #2 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 6.3990 - num_tokens: 131992.0000 - num_tokens_no_oov: 127599.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0029 - accuracy_no_oov: 0.0026 - accuracy_no_oov_no_eos: 0.0027Sampling 10 new clients.\n",
      "Round: 2\n",
      "   Loss: 8.91316414\n",
      "   num_batches: 105\n",
      "   num_examples: 1619\n",
      "   num_tokens: 20921\n",
      "   num_tokens_no_oov: 20274\n",
      "   accuracy: 0.00048\n",
      "   accuracy_no_oov: 0.00044\n",
      "Evaluating before round #3 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 112ms/step - loss: 6.6010 - num_tokens: 136704.0000 - num_tokens_no_oov: 132273.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0020 - accuracy_no_oov: 0.0016 - accuracy_no_oov_no_eos: 0.0016Sampling 10 new clients.\n",
      "Round: 3\n",
      "   Loss: 7.97288084\n",
      "   num_batches: 167\n",
      "   num_examples: 2592\n",
      "   num_tokens: 30596\n",
      "   num_tokens_no_oov: 29683\n",
      "   accuracy: 0.00023\n",
      "   accuracy_no_oov: 0.00024\n",
      "Evaluating before round #4 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 110ms/step - loss: 6.7229 - num_tokens: 139534.0000 - num_tokens_no_oov: 135302.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 8.5284e-04 - accuracy_no_oov: 6.7996e-04 - accuracy_no_oov_no_eos: 7.1709e-04Sampling 10 new clients.\n",
      "Round: 4\n",
      "   Loss: 7.14308786\n",
      "   num_batches: 210\n",
      "   num_examples: 3286\n",
      "   num_tokens: 42544\n",
      "   num_tokens_no_oov: 41437\n",
      "   accuracy: 0.00009\n",
      "   accuracy_no_oov: 0.00010\n",
      "Evaluating before round #5 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 118ms/step - loss: 6.0528 - num_tokens: 124236.0000 - num_tokens_no_oov: 120435.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 1.9318e-04 - accuracy_no_oov: 1.9928e-04 - accuracy_no_oov_no_eos: 2.1308e-04Sampling 10 new clients.\n",
      "Round: 5\n",
      "   Loss: 5.74621058\n",
      "   num_batches: 359\n",
      "   num_examples: 5640\n",
      "   num_tokens: 67868\n",
      "   num_tokens_no_oov: 66155\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #6 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 6.5454 - num_tokens: 135917.0000 - num_tokens_no_oov: 131598.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 1.1036e-04 - accuracy_no_oov: 9.8786e-05 - accuracy_no_oov_no_eos: 1.0445e-04Sampling 10 new clients.\n",
      "Round: 6\n",
      "   Loss: 6.20211172\n",
      "   num_batches: 388\n",
      "   num_examples: 6111\n",
      "   num_tokens: 82073\n",
      "   num_tokens_no_oov: 79859\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #7 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 110ms/step - loss: 6.5458 - num_tokens: 136301.0000 - num_tokens_no_oov: 132377.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 7.3367e-06 - accuracy_no_oov: 7.5542e-06 - accuracy_no_oov_no_eos: 7.9882e-06Sampling 10 new clients.\n",
      "Round: 7\n",
      "   Loss: 7.83641386\n",
      "   num_batches: 127\n",
      "   num_examples: 1935\n",
      "   num_tokens: 23500\n",
      "   num_tokens_no_oov: 22696\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #8 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 121ms/step - loss: 6.2327 - num_tokens: 129758.0000 - num_tokens_no_oov: 125552.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 4.6240e-05 - accuracy_no_oov: 4.7789e-05 - accuracy_no_oov_no_eos: 5.0812e-0545ms/step - loss: 6.1103 - num_tokens: 64769.0000 - num_tokens_no_oov: 62688.0000 - num_batches: 51.0000 - num_examples: 5100.0000 - accuracy: 4Sampling 10 new clients.\n",
      "Round: 8\n",
      "   Loss: 6.56630516\n",
      "   num_batches: 271\n",
      "   num_examples: 4267\n",
      "   num_tokens: 59421\n",
      "   num_tokens_no_oov: 57596\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #9 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 110ms/step - loss: 6.3145 - num_tokens: 132638.0000 - num_tokens_no_oov: 128373.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 3.0157e-05 - accuracy_no_oov: 3.1159e-05 - accuracy_no_oov_no_eos: 3.3101e-05Sampling 10 new clients.\n",
      "Round: 9\n",
      "   Loss: 7.12601376\n",
      "   num_batches: 179\n",
      "   num_examples: 2799\n",
      "   num_tokens: 39039\n",
      "   num_tokens_no_oov: 37987\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #10 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 114ms/step - loss: 6.1469 - num_tokens: 130339.0000 - num_tokens_no_oov: 126390.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 2.3017e-05 - accuracy_no_oov: 2.3736e-05 - accuracy_no_oov_no_eos: 2.5214e-05Sampling 10 new clients.\n",
      "Round: 10\n",
      "   Loss: 6.94385195\n",
      "   num_batches: 159\n",
      "   num_examples: 2463\n",
      "   num_tokens: 33154\n",
      "   num_tokens_no_oov: 32254\n",
      "   accuracy: 0.00003\n",
      "   accuracy_no_oov: 0.00003\n",
      "Evaluating before round #11 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 6.1070 - num_tokens: 131051.0000 - num_tokens_no_oov: 127111.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 11\n",
      "   Loss: 6.56374788\n",
      "   num_batches: 201\n",
      "   num_examples: 3138\n",
      "   num_tokens: 42563\n",
      "   num_tokens_no_oov: 41360\n",
      "   accuracy: 0.00002\n",
      "   accuracy_no_oov: 0.00002\n",
      "Evaluating before round #12 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 115ms/step - loss: 6.0432 - num_tokens: 131880.0000 - num_tokens_no_oov: 127352.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 12\n",
      "   Loss: 6.61138535\n",
      "   num_batches: 158\n",
      "   num_examples: 2455\n",
      "   num_tokens: 32001\n",
      "   num_tokens_no_oov: 31131\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #13 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 112ms/step - loss: 6.1570 - num_tokens: 137245.0000 - num_tokens_no_oov: 132314.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 13\n",
      "   Loss: 6.31612301\n",
      "   num_batches: 166\n",
      "   num_examples: 2594\n",
      "   num_tokens: 35142\n",
      "   num_tokens_no_oov: 34125\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #14 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 5.9545 - num_tokens: 135071.0000 - num_tokens_no_oov: 130192.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 14\n",
      "   Loss: 6.00530434\n",
      "   num_batches: 193\n",
      "   num_examples: 3008\n",
      "   num_tokens: 36170\n",
      "   num_tokens_no_oov: 35109\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #15 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 112ms/step - loss: 6.0001 - num_tokens: 139535.0000 - num_tokens_no_oov: 135023.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 15\n",
      "   Loss: 6.35087729\n",
      "   num_batches: 126\n",
      "   num_examples: 1921\n",
      "   num_tokens: 24363\n",
      "   num_tokens_no_oov: 23568\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #16 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 5.5504 - num_tokens: 130268.0000 - num_tokens_no_oov: 126352.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 1.5353e-05 - accuracy_no_oov: 1.5829e-05 - accuracy_no_oov_no_eos: 1.6845e-05Sampling 10 new clients.\n",
      "Round: 16\n",
      "   Loss: 5.65327501\n",
      "   num_batches: 194\n",
      "   num_examples: 3028\n",
      "   num_tokens: 37268\n",
      "   num_tokens_no_oov: 36394\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #17 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 109ms/step - loss: 5.1357 - num_tokens: 121350.0000 - num_tokens_no_oov: 117118.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 8.2406e-06 - accuracy_no_oov: 8.5384e-06 - accuracy_no_oov_no_eos: 9.1481e-06Sampling 10 new clients.\n",
      "Round: 17\n",
      "   Loss: 5.86628866\n",
      "   num_batches: 200\n",
      "   num_examples: 3100\n",
      "   num_tokens: 41290\n",
      "   num_tokens_no_oov: 39968\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #18 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 111ms/step - loss: 5.4463 - num_tokens: 133527.0000 - num_tokens_no_oov: 129549.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 18\n",
      "   Loss: 4.73102474\n",
      "   num_batches: 249\n",
      "   num_examples: 3903\n",
      "   num_tokens: 45859\n",
      "   num_tokens_no_oov: 44583\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #19 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 5.4700 - num_tokens: 136991.0000 - num_tokens_no_oov: 132775.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 19\n",
      "   Loss: 5.60857630\n",
      "   num_batches: 130\n",
      "   num_examples: 2021\n",
      "   num_tokens: 25380\n",
      "   num_tokens_no_oov: 24641\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #20 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 117ms/step - loss: 5.2304 - num_tokens: 132574.0000 - num_tokens_no_oov: 128460.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 20\n",
      "   Loss: 5.78391457\n",
      "   num_batches: 131\n",
      "   num_examples: 2035\n",
      "   num_tokens: 27217\n",
      "   num_tokens_no_oov: 26364\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #21 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 110ms/step - loss: 4.9950 - num_tokens: 128127.0000 - num_tokens_no_oov: 124433.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 21\n",
      "   Loss: 5.47906256\n",
      "   num_batches: 238\n",
      "   num_examples: 3736\n",
      "   num_tokens: 51442\n",
      "   num_tokens_no_oov: 50144\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #22 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 13s 126ms/step - loss: 5.0032 - num_tokens: 129689.0000 - num_tokens_no_oov: 125345.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 22\n",
      "   Loss: 5.81505585\n",
      "   num_batches: 149\n",
      "   num_examples: 2308\n",
      "   num_tokens: 33457\n",
      "   num_tokens_no_oov: 32215\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #23 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 13s 133ms/step - loss: 4.9425 - num_tokens: 129320.0000 - num_tokens_no_oov: 125432.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 23\n",
      "   Loss: 5.51555490\n",
      "   num_batches: 169\n",
      "   num_examples: 2591\n",
      "   num_tokens: 34113\n",
      "   num_tokens_no_oov: 32913\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #24 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 117ms/step - loss: 4.9177 - num_tokens: 130345.0000 - num_tokens_no_oov: 126666.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 24\n",
      "   Loss: 5.76888466\n",
      "   num_batches: 203\n",
      "   num_examples: 3159\n",
      "   num_tokens: 45769\n",
      "   num_tokens_no_oov: 44613\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #25 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 114ms/step - loss: 5.0862 - num_tokens: 134683.0000 - num_tokens_no_oov: 130150.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 25\n",
      "   Loss: 5.38024235\n",
      "   num_batches: 193\n",
      "   num_examples: 3012\n",
      "   num_tokens: 43036\n",
      "   num_tokens_no_oov: 41932\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #26 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 115ms/step - loss: 5.0143 - num_tokens: 132371.0000 - num_tokens_no_oov: 128243.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 26\n",
      "   Loss: 5.39824247\n",
      "   num_batches: 189\n",
      "   num_examples: 2960\n",
      "   num_tokens: 39418\n",
      "   num_tokens_no_oov: 38270\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #27 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 114ms/step - loss: 5.0374 - num_tokens: 132630.0000 - num_tokens_no_oov: 128650.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 27\n",
      "   Loss: 5.28744316\n",
      "   num_batches: 217\n",
      "   num_examples: 3412\n",
      "   num_tokens: 46313\n",
      "   num_tokens_no_oov: 44539\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #28 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 5.0069 - num_tokens: 131425.0000 - num_tokens_no_oov: 127423.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 28\n",
      "   Loss: 4.70133257\n",
      "   num_batches: 327\n",
      "   num_examples: 5173\n",
      "   num_tokens: 66747\n",
      "   num_tokens_no_oov: 64704\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #29 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 5.2212 - num_tokens: 135200.0000 - num_tokens_no_oov: 131653.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 29\n",
      "   Loss: 5.06162071\n",
      "   num_batches: 253\n",
      "   num_examples: 3980\n",
      "   num_tokens: 51012\n",
      "   num_tokens_no_oov: 49493\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #30 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 5.0071 - num_tokens: 130275.0000 - num_tokens_no_oov: 125707.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 30\n",
      "   Loss: 5.19401646\n",
      "   num_batches: 217\n",
      "   num_examples: 3407\n",
      "   num_tokens: 45280\n",
      "   num_tokens_no_oov: 44154\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #31 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 13s 127ms/step - loss: 5.1497 - num_tokens: 132863.0000 - num_tokens_no_oov: 128819.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 31\n",
      "   Loss: 5.09402084\n",
      "   num_batches: 304\n",
      "   num_examples: 4810\n",
      "   num_tokens: 65207\n",
      "   num_tokens_no_oov: 63284\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #32 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 114ms/step - loss: 5.1760 - num_tokens: 132689.0000 - num_tokens_no_oov: 128771.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 32\n",
      "   Loss: 5.20843601\n",
      "   num_batches: 111\n",
      "   num_examples: 1715\n",
      "   num_tokens: 22406\n",
      "   num_tokens_no_oov: 21436\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #33 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 120ms/step - loss: 5.3903 - num_tokens: 137027.0000 - num_tokens_no_oov: 132710.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 33\n",
      "   Loss: 5.01629591\n",
      "   num_batches: 249\n",
      "   num_examples: 3915\n",
      "   num_tokens: 51898\n",
      "   num_tokens_no_oov: 50459\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #34 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 112ms/step - loss: 5.2394 - num_tokens: 133097.0000 - num_tokens_no_oov: 128194.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 34\n",
      "   Loss: 5.00943422\n",
      "   num_batches: 158\n",
      "   num_examples: 2440\n",
      "   num_tokens: 31316\n",
      "   num_tokens_no_oov: 30257\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #35 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 112ms/step - loss: 5.3732 - num_tokens: 134165.0000 - num_tokens_no_oov: 130091.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 35\n",
      "   Loss: 4.87090349\n",
      "   num_batches: 444\n",
      "   num_examples: 7035\n",
      "   num_tokens: 102311\n",
      "   num_tokens_no_oov: 99357\n",
      "   accuracy: 0.00943\n",
      "   accuracy_no_oov: 0.00864\n",
      "Evaluating before round #36 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 116ms/step - loss: 5.3588 - num_tokens: 135118.0000 - num_tokens_no_oov: 131120.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 36\n",
      "   Loss: 5.44980812\n",
      "   num_batches: 155\n",
      "   num_examples: 2376\n",
      "   num_tokens: 34539\n",
      "   num_tokens_no_oov: 33700\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #37 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 114ms/step - loss: 5.0211 - num_tokens: 127154.0000 - num_tokens_no_oov: 123238.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 37\n",
      "   Loss: 4.79563618\n",
      "   num_batches: 123\n",
      "   num_examples: 1898\n",
      "   num_tokens: 24919\n",
      "   num_tokens_no_oov: 24298\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #38 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 114ms/step - loss: 4.8867 - num_tokens: 123895.0000 - num_tokens_no_oov: 120294.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 38\n",
      "   Loss: 4.88937187\n",
      "   num_batches: 297\n",
      "   num_examples: 4680\n",
      "   num_tokens: 62957\n",
      "   num_tokens_no_oov: 60924\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #39 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 118ms/step - loss: 5.2792 - num_tokens: 132917.0000 - num_tokens_no_oov: 128349.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 39\n",
      "   Loss: 5.07269526\n",
      "   num_batches: 385\n",
      "   num_examples: 6086\n",
      "   num_tokens: 89806\n",
      "   num_tokens_no_oov: 87604\n",
      "   accuracy: 0.00014\n",
      "   accuracy_no_oov: 0.00015\n",
      "Evaluating before round #40 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 119ms/step - loss: 5.1363 - num_tokens: 130256.0000 - num_tokens_no_oov: 126292.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 40\n",
      "   Loss: 4.84020758\n",
      "   num_batches: 174\n",
      "   num_examples: 2697\n",
      "   num_tokens: 34468\n",
      "   num_tokens_no_oov: 33691\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #41 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 116ms/step - loss: 5.3818 - num_tokens: 136154.0000 - num_tokens_no_oov: 131894.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 41\n",
      "   Loss: 4.75243139\n",
      "   num_batches: 374\n",
      "   num_examples: 5912\n",
      "   num_tokens: 80530\n",
      "   num_tokens_no_oov: 78437\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #42 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 117ms/step - loss: 5.1480 - num_tokens: 130945.0000 - num_tokens_no_oov: 127009.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 42\n",
      "   Loss: 4.56425476\n",
      "   num_batches: 171\n",
      "   num_examples: 2675\n",
      "   num_tokens: 32031\n",
      "   num_tokens_no_oov: 30688\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #43 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 119ms/step - loss: 4.9101 - num_tokens: 126467.0000 - num_tokens_no_oov: 122210.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 43\n",
      "   Loss: 5.07414436\n",
      "   num_batches: 247\n",
      "   num_examples: 3875\n",
      "   num_tokens: 54273\n",
      "   num_tokens_no_oov: 52805\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #44 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 114ms/step - loss: 4.6336 - num_tokens: 119584.0000 - num_tokens_no_oov: 115976.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 44\n",
      "   Loss: 4.84156704\n",
      "   num_batches: 220\n",
      "   num_examples: 3449\n",
      "   num_tokens: 46041\n",
      "   num_tokens_no_oov: 44453\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #45 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 113ms/step - loss: 5.0885 - num_tokens: 131865.0000 - num_tokens_no_oov: 127925.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 45\n",
      "   Loss: 4.48022413\n",
      "   num_batches: 308\n",
      "   num_examples: 4843\n",
      "   num_tokens: 61048\n",
      "   num_tokens_no_oov: 59450\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #46 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 11s 114ms/step - loss: 5.0272 - num_tokens: 132277.0000 - num_tokens_no_oov: 128045.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 46\n",
      "   Loss: 4.75998735\n",
      "   num_batches: 178\n",
      "   num_examples: 2771\n",
      "   num_tokens: 35949\n",
      "   num_tokens_no_oov: 34865\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #47 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 13s 129ms/step - loss: 4.8666 - num_tokens: 128584.0000 - num_tokens_no_oov: 124614.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n",
      "Round: 47\n",
      "   Loss: 5.04955435\n",
      "   num_batches: 270\n",
      "   num_examples: 4244\n",
      "   num_tokens: 60949\n",
      "   num_tokens_no_oov: 59393\n",
      "   accuracy: 0.00000\n",
      "   accuracy_no_oov: 0.00000\n",
      "Evaluating before round #48 on 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel_stremmel/anaconda3/envs/tff/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:64: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100/Unknown - 12s 117ms/step - loss: 4.8510 - num_tokens: 129312.0000 - num_tokens_no_oov: 125461.0000 - num_batches: 100.0000 - num_examples: 10000.0000 - accuracy: 0.0000e+00 - accuracy_no_oov: 0.0000e+00 - accuracy_no_oov_no_eos: 0.0000e+00Sampling 10 new clients.\n"
     ]
    }
   ],
   "source": [
    "for round_num in range(0, NUM_ROUNDS):\n",
    "\n",
    "    # Examine validation metrics\n",
    "    print('Evaluating before round #{} on {} examples.'.format(round_num, NUM_VALIDATION_EXAMPLES))\n",
    "    validation.keras_evaluate(state=server_state,\n",
    "                              val_dataset=val_data,\n",
    "                              extended_vocab_size=extended_vocab_size,\n",
    "                              vocab_size=VOCAB_SIZE,\n",
    "                              embedding_dim=EMBEDDING_DIM,\n",
    "                              embedding_matrix=embedding_matrix,\n",
    "                              rnn_units=RNN_UNITS,\n",
    "                              metrics_tracker=val_metrics_tracker)\n",
    "\n",
    "    # Sample train clients to create a train dataset\n",
    "    print('Sampling {} new clients.'.format(NUM_TRAIN_CLIENTS))\n",
    "    train_clients = federated.get_sample_clients(dataset=train_data, num_clients=NUM_TRAIN_CLIENTS)\n",
    "    train_datasets = [train_data.create_tf_dataset_for_client(client) for client in train_clients]\n",
    "\n",
    "    # Apply federated training round\n",
    "    server_state, server_metrics = iterative_process.next(server_state, train_datasets)\n",
    "\n",
    "    # Examine training metrics\n",
    "    print('Round: {}'.format(round_num))\n",
    "    print('   Loss: {:.8f}'.format(server_metrics.loss))\n",
    "    print('   num_batches: {}'.format(server_metrics.num_batches))\n",
    "    print('   num_examples: {}'.format(server_metrics.num_examples))\n",
    "    print('   num_tokens: {}'.format(server_metrics.num_tokens))\n",
    "    print('   num_tokens_no_oov: {}'.format(server_metrics.num_tokens_no_oov))\n",
    "    print('   accuracy: {:.5f}'.format(server_metrics.accuracy))\n",
    "    print('   accuracy_no_oov: {:.5f}'.format(server_metrics.accuracy_no_oov))\n",
    "\n",
    "    # Add train metrics to tracker\n",
    "    train_metrics_tracker.add_metrics_by_name('loss', server_metrics.loss)\n",
    "    train_metrics_tracker.add_metrics_by_name('accuracy', server_metrics.accuracy)\n",
    "    train_metrics_tracker.add_metrics_by_name('num_examples', server_metrics.num_examples)\n",
    "    train_metrics_tracker.add_metrics_by_name('num_tokens', server_metrics.num_tokens)\n",
    "    train_metrics_tracker.add_metrics_by_name('num_tokens_no_oov', server_metrics.num_tokens_no_oov)\n",
    "        \n",
    "    # Save loss and accuracy from train and validation sets\n",
    "    np.save(SAV + 'train_loss.npy', train_metrics_tracker.get_metrics_by_name('loss'))\n",
    "    np.save(SAV + 'val_loss.npy', val_metrics_tracker.get_metrics_by_name('loss'))\n",
    "    np.save(SAV + 'train_accuracy.npy', train_metrics_tracker.get_metrics_by_name('accuracy'))\n",
    "    np.save(SAV + 'val_accuracy.npy', val_metrics_tracker.get_metrics_by_name('accuracy'))\n",
    "        \n",
    "    # Save train sample stats\n",
    "    np.save(SAV + 'num_examples.npy', train_metrics_tracker.get_metrics_by_name('num_examples'))\n",
    "    np.save(SAV + 'num_tokens.npy', train_metrics_tracker.get_metrics_by_name('num_tokens'))\n",
    "    np.save(SAV + 'num_tokens_no_oov.npy', train_metrics_tracker.get_metrics_by_name('num_tokens_no_oov'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Plot Title Based on Training Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_config = 'Clients: {}, Max Elements per Client: {}, Max Seq Len: {}, Num Rounds: {}'.format(\n",
    "    NUM_TRAIN_CLIENTS, MAX_ELEMENTS_PER_USER, MAX_SEQ_LENGTH, NUM_ROUNDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Train and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "x_axis = range(0, NUM_ROUNDS)\n",
    "ax.plot(x_axis, train_metrics_tracker.get_metrics_by_name('loss'), label='Train')\n",
    "ax.plot(x_axis, val_metrics_tracker.get_metrics_by_name('loss'), label='Val')\n",
    "ax.legend(loc='best', prop={'size': 15})\n",
    "plt.title('Loss by Epoch - {}'.format(round_config), fontsize=18)\n",
    "plt.xlabel('Epochs', fontsize=18)\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAV + 'Loss by Epoch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pload Train and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "x_axis = range(0, NUM_ROUNDS)\n",
    "ax.plot(x_axis, train_metrics_tracker.get_metrics_by_name('accuracy'), label='Train')\n",
    "ax.plot(x_axis, val_metrics_tracker.get_metrics_by_name('accuracy'), label='Val')\n",
    "ax.legend(loc='best', prop={'size': 15})\n",
    "plt.title('Accuracy by Epoch - {}'.format(round_config), fontsize=18)\n",
    "plt.xlabel('Epochs', fontsize=18)\n",
    "plt.ylabel('Accuracy', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAV + 'Accuracy by Epoch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Sample Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = np.load(SAV + 'num_examples.npy')\n",
    "tokens = np.load(SAV + 'num_tokens.npy')\n",
    "tokens_no_oov = np.load(SAV + 'num_tokens_no_oov.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Train Sample Means and Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_stats = ['Examples', 'Tokens', 'Tokens No OOV']\n",
    "means = [np.mean(examples), np.mean(tokens), np.mean(tokens_no_oov)]\n",
    "stdvs = [np.std(examples), np.std(tokens), np.std(tokens_no_oov)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Train Sample Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "x_pos = np.arange(len(train_sample_stats))\n",
    "ax.bar(x_pos, means, yerr=stdvs, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylabel('Sample Mean +- 1 Stdv')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(train_sample_stats)\n",
    "ax.set_title('Train Sample Means - {}'.format(round_config))\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAV + '{} Round Train Sample Means.png'.format(NUM_ROUNDS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.hist(examples, alpha=0.4, label='Num Examples')\n",
    "plt.hist(tokens, alpha=0.4, label='Num Tokens')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Train Sample Distributions - {}'.format(round_config))\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAV + '{} Round Train Sample Distributions.png'.format(NUM_ROUNDS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.hist(examples, alpha=0.8, label='Num Examples')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Train Sample Distribution - {}'.format(round_config))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.hist(tokens, alpha=0.8, label='Num Tokens')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Train Sample Distribution - {}'.format(round_config))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.hist(tokens_no_oov, alpha=0.8, label='Num Tokens No OOV')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Train Sample Distribution - {}'.format(round_config))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed",
   "language": "python",
   "name": "fed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
